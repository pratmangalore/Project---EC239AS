{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import importlib \n",
    "import preprocessing\n",
    "importlib.reload(preprocessing)\n",
    "from preprocessing import *\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 3 0 ... 3 3 2]\n"
     ]
    }
   ],
   "source": [
    "X_train = np.load('../../Project_Data/X_train_valid.npy')\n",
    "y_train = np.load('../../Project_Data/y_train_valid.npy')\n",
    "X_test = np.load('../../Project_Data/X_test.npy')\n",
    "y_test = np.load('../../Project_Data/y_test.npy')\n",
    "\n",
    "X_train_mean = X_train.mean(0)\n",
    "X_train_var = np.sqrt(X_train.var(0))\n",
    "\n",
    "X_train -= X_train_mean\n",
    "X_train /= X_train_var\n",
    "X_test -= X_train_mean\n",
    "X_test /= X_train_var\n",
    "\n",
    "X_train = np.transpose(X_train, (0, 2, 1))\n",
    "X_test = np.transpose(X_test, (0, 2, 1))\n",
    "\n",
    "y_train = y_train - np.min(y_train)\n",
    "y_test = y_test - np.min(y_test)\n",
    "    \n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn_model(features, labels, mode, params):\n",
    "  \n",
    "  num_hidden_layers = len(params['hidden_layers'])  \n",
    "  \n",
    "  input_layer = features[\"x\"]    \n",
    "  cell1 = tf.nn.rnn_cell.LSTMCell(name = 'cell1', num_units = params['hidden_layers'][0])\n",
    "  outputs, state = tf.nn.dynamic_rnn(cell=cell1,\n",
    "                                   inputs=input_layer,\n",
    "                                   dtype=tf.float64)\n",
    "  outputs = tf.nn.relu(outputs)      \n",
    "  outputs = tf.layers.dropout(inputs=outputs, rate=0.5, training=(mode==tf.estimator.ModeKeys.TRAIN))\n",
    "  \n",
    "  for i in range(num_hidden_layers-1):  \n",
    "      cell = tf.nn.rnn_cell.LSTMCell(name = 'cell'+str(i+2),num_units = params['hidden_layers'][i+1])\n",
    "      outputs, state = tf.nn.dynamic_rnn(cell=cell,\n",
    "                                       inputs=outputs,\n",
    "                                       dtype=tf.float64)\n",
    "      outputs = tf.nn.relu(outputs)\n",
    "  \n",
    "  #FLatten the output of LSTM layers\n",
    "  outputs = tf.contrib.layers.flatten(outputs) \n",
    "\n",
    "  # FC Layer\n",
    "  logits = tf.layers.dense(inputs=outputs, units=params['num_classes'])\n",
    "\n",
    "  predictions = {\n",
    "      # Generate predictions (for PREDICT and EVAL mode)\n",
    "      \"classes\": tf.argmax(input=logits, axis=1),\n",
    "      # Add `softmax_tensor` to the graph. It is used for PREDICT and by the\n",
    "      # `logging_hook`.\n",
    "      \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "  }\n",
    "\n",
    "  if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "\n",
    "  # Calculate Loss (for both TRAIN and EVAL modes)\n",
    "  loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "  tf.summary.scalar('loss', loss)\n",
    "      \n",
    "\n",
    "  # Configure the Training Op (for TRAIN mode)\n",
    "  if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=params['learning_rate'])\n",
    "    train_op = optimizer.minimize(\n",
    "        loss=loss,\n",
    "        global_step=tf.train.get_global_step())\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "\n",
    "  # Add evaluation metrics (for EVAL mode)\n",
    "  eval_metric_ops = {\n",
    "      \"accuracy\": tf.metrics.accuracy(\n",
    "          labels=labels, predictions=predictions[\"classes\"])}\n",
    "  return tf.estimator.EstimatorSpec(\n",
    "      mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)\n",
    "\n",
    "  merged = tf.summary.merge_all()\n",
    "  train_writer = tf.summary.FileWriter(FLAGS.summaries_dir + '/train',\n",
    "                                      sess.graph)\n",
    "  test_writer = tf.summary.FileWriter(FLAGS.summaries_dir + '/test')\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "eeg_classifier = tf.estimator.Estimator(model_fn=rnn_model, model_dir=\"models/lstmmodel1/\", \n",
    "                                        params = {'hidden_layers' : [32, 32], 'num_classes' : 4, 'learning_rate' : 0.001})\n",
    "tensors_to_log = {\"probabilities\": \"softmax_tensor\"}\n",
    "logging_hook = tf.train.LoggingTensorHook(\n",
    "  tensors=tensors_to_log, every_n_iter=50)\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": X_train},\n",
    "    y=y_train,\n",
    "    batch_size=64,\n",
    "    num_epochs=20,\n",
    "    shuffle=True)\n",
    "\n",
    "eeg_classifier.train(\n",
    "    input_fn=train_input_fn,\n",
    "    steps=100,\n",
    "    hooks=[logging_hook])\n",
    "\n",
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": X_test},\n",
    "    y=y_test,\n",
    "    num_epochs=1,\n",
    "    shuffle=False)\n",
    "eval_results = eeg_classifier.evaluate(input_fn=eval_input_fn)\n",
    "print(eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_classifier = tf.estimator.Estimator(model_fn=rnn_model, model_dir=\"models/lstmmodel2/\", \n",
    "                                        params = {'hidden_layers' : [32, 32, 32], 'num_classes' : 4, 'learning_rate' : 0.001})\n",
    "tensors_to_log = {\"probabilities\": \"softmax_tensor\"}\n",
    "logging_hook = tf.train.LoggingTensorHook(\n",
    "  tensors=tensors_to_log, every_n_iter=50)\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": X_train},\n",
    "    y=y_train,\n",
    "    batch_size=100,\n",
    "    num_epochs=20,\n",
    "    shuffle=True)\n",
    "\n",
    "eeg_classifier.train(\n",
    "    input_fn=train_input_fn,\n",
    "    steps=100,\n",
    "    hooks=[logging_hook])\n",
    "\n",
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": X_test},\n",
    "    y=y_test,\n",
    "    num_epochs=1,\n",
    "    shuffle=False)\n",
    "eval_results = eeg_classifier.evaluate(input_fn=eval_input_fn)\n",
    "print(eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_classifier = tf.estimator.Estimator(model_fn=rnn_model, model_dir=\"models/lstmmodel3/\", \n",
    "                                        params = {'hidden_layers' : [32, 32], 'num_classes' : 4, 'learning_rate' : 0.001})\n",
    "tensors_to_log = {\"probabilities\": \"softmax_tensor\"}\n",
    "logging_hook = tf.train.LoggingTensorHook(\n",
    "  tensors=tensors_to_log, every_n_iter=50)\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": X_train},\n",
    "    y=y_train,\n",
    "    batch_size=100,\n",
    "    num_epochs=20,\n",
    "    shuffle=True)\n",
    "\n",
    "eeg_classifier.train(\n",
    "    input_fn=train_input_fn,\n",
    "    steps=100,\n",
    "    hooks=[logging_hook])\n",
    "\n",
    "eval_train_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": X_train},\n",
    "    y=y_train,\n",
    "    num_epochs=1,\n",
    "    shuffle=False)\n",
    "eval_train_results = eeg_classifier.evaluate(input_fn=eval_train_fn)\n",
    "\n",
    "eval_test_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": X_test},\n",
    "    y=y_test,\n",
    "    num_epochs=1,\n",
    "    shuffle=False)\n",
    "eval_test_results = eeg_classifier.evaluate(input_fn=eval_test_fn)\n",
    "print('Train results are:',eval_train_results)\n",
    "print('Test results are:',eval_test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_classifier = tf.estimator.Estimator(model_fn=rnn_model, model_dir=\"models/lstmmodel4/\", \n",
    "                                        params = {'hidden_layers' : [32, 32], 'num_classes' : 4, 'learning_rate' : 0.001})\n",
    "tensors_to_log = {\"probabilities\": \"softmax_tensor\"}\n",
    "logging_hook = tf.train.LoggingTensorHook(\n",
    "  tensors=tensors_to_log, every_n_iter=50)\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": X_train},\n",
    "    y=y_train,\n",
    "    batch_size=100,\n",
    "    num_epochs=20,\n",
    "    shuffle=True)\n",
    "\n",
    "eeg_classifier.train(\n",
    "    input_fn=train_input_fn,\n",
    "    steps=100,\n",
    "    hooks=[logging_hook])\n",
    "\n",
    "eval_train_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": X_train},\n",
    "    y=y_train,\n",
    "    num_epochs=1,\n",
    "    shuffle=False)\n",
    "eval_train_results = eeg_classifier.evaluate(input_fn=eval_train_fn)\n",
    "\n",
    "eval_test_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": X_test},\n",
    "    y=y_test,\n",
    "    num_epochs=1,\n",
    "    shuffle=False)\n",
    "eval_test_results = eeg_classifier.evaluate(input_fn=eval_test_fn)\n",
    "print('Train results are:',eval_train_results)\n",
    "print('Test results are:',eval_test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Unable to open file (unable to open file: name = 'data/A01T_slice.mat', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-3e6eed1edca6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimport_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevery\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_total\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m eeg_classifier = tf.estimator.Estimator(model_fn=rnn_model, model_dir=\"models/lstmmodel5/\", \n\u001b[1;32m      4\u001b[0m                                         params = {'hidden_layers' : [64, 64], 'num_classes' : 4, 'learning_rate' : 0.001})\n\u001b[1;32m      5\u001b[0m \u001b[0mtensors_to_log\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"probabilities\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"softmax_tensor\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Project_Code/RNN/preprocessing.py\u001b[0m in \u001b[0;36mimport_data\u001b[0;34m(every)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mA01T\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/A0'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'T_slice.mat'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mX1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA01T\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0melectrodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, **kwds)\u001b[0m\n\u001b[1;32m    392\u001b[0m                 fid = make_fid(name, mode, userblock_size,\n\u001b[1;32m    393\u001b[0m                                \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmake_fcpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m                                swmr=swmr)\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Unable to open file (unable to open file: name = 'data/A01T_slice.mat', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "eeg_classifier = tf.estimator.Estimator(model_fn=rnn_model, model_dir=\"models/lstmmodel5/\", \n",
    "                                        params = {'hidden_layers' : [64, 64], 'num_classes' : 4, 'learning_rate' : 0.001})\n",
    "tensors_to_log = {\"probabilities\": \"softmax_tensor\"}\n",
    "logging_hook = tf.train.LoggingTensorHook(\n",
    "  tensors=tensors_to_log, every_n_iter=50)\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": X_train},\n",
    "    y=y_train,\n",
    "    batch_size=100,\n",
    "    num_epochs=20,\n",
    "    shuffle=True)\n",
    "\n",
    "eeg_classifier.train(\n",
    "    input_fn=train_input_fn,\n",
    "    steps=100,\n",
    "    hooks=[logging_hook])\n",
    "\n",
    "eval_train_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": X_train},\n",
    "    y=y_train,\n",
    "    num_epochs=1,\n",
    "    shuffle=False)\n",
    "eval_train_results = eeg_classifier.evaluate(input_fn=eval_train_fn)\n",
    "\n",
    "eval_test_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": X_test},\n",
    "    y=y_test,\n",
    "    num_epochs=1,\n",
    "    shuffle=False)\n",
    "eval_test_results = eeg_classifier.evaluate(input_fn=eval_test_fn)\n",
    "print('Train results are:',eval_train_results)\n",
    "print('Test results are:',eval_test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_classifier = tf.estimator.Estimator(model_fn=rnn_model, model_dir=\"models/lstmmodel6/\", \n",
    "                                        params = {'hidden_layers' : [32, 32, 32], 'num_classes' : 4, 'learning_rate' : 0.001})\n",
    "tensors_to_log = {\"probabilities\": \"softmax_tensor\"}\n",
    "logging_hook = tf.train.LoggingTensorHook(\n",
    "  tensors=tensors_to_log, every_n_iter=50)\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": X_train},\n",
    "    y=y_train,\n",
    "    batch_size=100,\n",
    "    num_epochs=20,\n",
    "    shuffle=True)\n",
    "\n",
    "eeg_classifier.train(\n",
    "    input_fn=train_input_fn,\n",
    "    steps=100,\n",
    "    hooks=[logging_hook])\n",
    "\n",
    "eval_train_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": X_train},\n",
    "    y=y_train,\n",
    "    num_epochs=1,\n",
    "    shuffle=False)\n",
    "eval_train_results = eeg_classifier.evaluate(input_fn=eval_train_fn)\n",
    "\n",
    "eval_test_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": X_test},\n",
    "    y=y_test,\n",
    "    num_epochs=1,\n",
    "    shuffle=False)\n",
    "eval_test_results = eeg_classifier.evaluate(input_fn=eval_test_fn)\n",
    "print('Train results are:',eval_train_results)\n",
    "print('Test results are:',eval_test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_classifier = tf.estimator.Estimator(model_fn=rnn_model, model_dir=\"models/lstmmodel7/\", \n",
    "                                        params = {'hidden_layers' : [64, 64, 64], 'num_classes' : 4, 'learning_rate' : 0.001})\n",
    "tensors_to_log = {\"probabilities\": \"softmax_tensor\"}\n",
    "logging_hook = tf.train.LoggingTensorHook(\n",
    "  tensors=tensors_to_log, every_n_iter=50)\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": X_train},\n",
    "    y=y_train,\n",
    "    batch_size=100,\n",
    "    num_epochs=20,\n",
    "    shuffle=True)\n",
    "\n",
    "eeg_classifier.train(\n",
    "    input_fn=train_input_fn,\n",
    "    steps=100,\n",
    "    hooks=[logging_hook])\n",
    "\n",
    "eval_train_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": X_train},\n",
    "    y=y_train,\n",
    "    num_epochs=1,\n",
    "    shuffle=False)\n",
    "eval_train_results = eeg_classifier.evaluate(input_fn=eval_train_fn)\n",
    "\n",
    "eval_test_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": X_test},\n",
    "    y=y_test,\n",
    "    num_epochs=1,\n",
    "    shuffle=False)\n",
    "eval_test_results = eeg_classifier.evaluate(input_fn=eval_test_fn)\n",
    "print('Train results are:',eval_train_results)\n",
    "print('Test results are:',eval_test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_classifier = tf.estimator.Estimator(model_fn=rnn_model, model_dir=\"models/lstmmodel8/\", \n",
    "                                        params = {'hidden_layers' : [128, 128], 'num_classes' : 4, 'learning_rate' : 0.001})\n",
    "tensors_to_log = {\"probabilities\": \"softmax_tensor\"}\n",
    "logging_hook = tf.train.LoggingTensorHook(\n",
    "  tensors=tensors_to_log, every_n_iter=50)\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": X_train},\n",
    "    y=y_train,\n",
    "    batch_size=100,\n",
    "    num_epochs=20,\n",
    "    shuffle=True)\n",
    "\n",
    "eeg_classifier.train(\n",
    "    input_fn=train_input_fn,\n",
    "    steps=100,\n",
    "    hooks=[logging_hook])\n",
    "\n",
    "eval_train_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": X_train},\n",
    "    y=y_train,\n",
    "    num_epochs=1,\n",
    "    shuffle=False)\n",
    "eval_train_results = eeg_classifier.evaluate(input_fn=eval_train_fn)\n",
    "\n",
    "eval_test_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": X_test},\n",
    "    y=y_test,\n",
    "    num_epochs=1,\n",
    "    shuffle=False)\n",
    "eval_test_results = eeg_classifier.evaluate(input_fn=eval_test_fn)\n",
    "print('Train results are:',eval_train_results)\n",
    "print('Test results are:',eval_test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_classifier = tf.estimator.Estimator(model_fn=rnn_model, model_dir=\"models/lstmmodel9/\", \n",
    "                                        params = {'hidden_layers' : [64,64], 'num_classes' : 4, 'learning_rate' : 0.001})\n",
    "tensors_to_log = {\"probabilities\": \"softmax_tensor\"}\n",
    "logging_hook = tf.train.LoggingTensorHook(\n",
    "  tensors=tensors_to_log, every_n_iter=50)\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": X_train},\n",
    "    y=y_train,\n",
    "    batch_size=100,\n",
    "    num_epochs=20,\n",
    "    shuffle=True)\n",
    "\n",
    "eeg_classifier.train(\n",
    "    input_fn=train_input_fn,\n",
    "    steps=100,\n",
    "    hooks=[logging_hook])\n",
    "\n",
    "eval_train_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": X_train},\n",
    "    y=y_train,\n",
    "    num_epochs=1,\n",
    "    shuffle=False)\n",
    "eval_train_results = eeg_classifier.evaluate(input_fn=eval_train_fn)\n",
    "\n",
    "eval_test_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": X_test},\n",
    "    y=y_test,\n",
    "    num_epochs=1,\n",
    "    shuffle=False)\n",
    "eval_test_results = eeg_classifier.evaluate(input_fn=eval_test_fn)\n",
    "print('Train results are:',eval_train_results)\n",
    "print('Test results are:',eval_test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_classifier = tf.estimator.Estimator(model_fn=rnn_model, model_dir=\"models/lstmmodel10/\", \n",
    "                                        params = {'hidden_layers' : [32,32], 'num_classes' : 4, 'learning_rate' : 0.001})\n",
    "tensors_to_log = {\"probabilities\": \"softmax_tensor\"}\n",
    "logging_hook = tf.train.LoggingTensorHook(\n",
    "  tensors=tensors_to_log, every_n_iter=50)\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": X_train},\n",
    "    y=y_train,\n",
    "    batch_size=100,\n",
    "    num_epochs=20,\n",
    "    shuffle=True)\n",
    "\n",
    "eeg_classifier.train(\n",
    "    input_fn=train_input_fn,\n",
    "    steps=100,\n",
    "    hooks=[logging_hook])\n",
    "\n",
    "eval_train_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": X_train},\n",
    "    y=y_train,\n",
    "    num_epochs=1,\n",
    "    shuffle=False)\n",
    "eval_train_results = eeg_classifier.evaluate(input_fn=eval_train_fn)\n",
    "\n",
    "eval_test_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": X_test},\n",
    "    y=y_test,\n",
    "    num_epochs=1,\n",
    "    shuffle=False)\n",
    "eval_test_results = eeg_classifier.evaluate(input_fn=eval_test_fn)\n",
    "print('Train results are:',eval_train_results)\n",
    "print('Test results are:',eval_test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_classifier = tf.estimator.Estimator(model_fn=rnn_model, \n",
    "                                        params = {'hidden_layers' : [64,64], 'num_classes' : 4, 'learning_rate' : 0.001})\n",
    "tensors_to_log = {\"probabilities\": \"softmax_tensor\"}\n",
    "logging_hook = tf.train.LoggingTensorHook(\n",
    "  tensors=tensors_to_log, every_n_iter=50)\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": X_train},\n",
    "    y=y_train,\n",
    "    batch_size=100,\n",
    "    num_epochs=20,\n",
    "    shuffle=True)\n",
    "\n",
    "eeg_classifier.train(\n",
    "    input_fn=train_input_fn,\n",
    "    steps=100,\n",
    "    hooks=[logging_hook])\n",
    "\n",
    "eval_train_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": X_train},\n",
    "    y=y_train,\n",
    "    num_epochs=1,\n",
    "    shuffle=False)\n",
    "eval_train_results = eeg_classifier.evaluate(input_fn=eval_train_fn)\n",
    "\n",
    "eval_test_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": X_test},\n",
    "    y=y_test,\n",
    "    num_epochs=1,\n",
    "    shuffle=False)\n",
    "eval_test_results = eeg_classifier.evaluate(input_fn=eval_test_fn)\n",
    "print('Train results are:',eval_train_results)\n",
    "print('Test results are:',eval_test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = import_data(every=False)\n",
    "X_train,X_test,y_train,y_test = train_test_total(X, y,standardize=False)\n",
    "eeg_classifier = tf.estimator.Estimator(model_fn=rnn_model, \n",
    "                                        params = {'hidden_layers' : [64,64], 'num_classes' : 4, 'learning_rate' : 0.001})\n",
    "tensors_to_log = {\"probabilities\": \"softmax_tensor\"}\n",
    "logging_hook = tf.train.LoggingTensorHook(\n",
    "  tensors=tensors_to_log, every_n_iter=50)\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": X_train},\n",
    "    y=y_train,\n",
    "    batch_size=100,\n",
    "    num_epochs=20,\n",
    "    shuffle=True)\n",
    "\n",
    "eeg_classifier.train(\n",
    "    input_fn=train_input_fn,\n",
    "    steps=100,\n",
    "    hooks=[logging_hook])\n",
    "\n",
    "eval_train_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": X_train},\n",
    "    y=y_train,\n",
    "    num_epochs=1,\n",
    "    shuffle=False)\n",
    "eval_train_results = eeg_classifier.evaluate(input_fn=eval_train_fn)\n",
    "\n",
    "eval_test_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": X_test},\n",
    "    y=y_test,\n",
    "    num_epochs=1,\n",
    "    shuffle=False)\n",
    "eval_test_results = eeg_classifier.evaluate(input_fn=eval_test_fn)\n",
    "print('Train results are:',eval_train_results)\n",
    "print('Test results are:',eval_test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = import_data(every=False)\n",
    "X_train,X_test,y_train,y_test = train_test_total(X, y)\n",
    "eeg_classifier = tf.estimator.Estimator(model_fn=rnn_model, \n",
    "                                        params = {'hidden_layers' : [32,32,32,32], 'num_classes' : 4, 'learning_rate' : 0.001})\n",
    "tensors_to_log = {\"probabilities\": \"softmax_tensor\"}\n",
    "logging_hook = tf.train.LoggingTensorHook(\n",
    "  tensors=tensors_to_log, every_n_iter=50)\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": X_train},\n",
    "    y=y_train,\n",
    "    batch_size=100,\n",
    "    num_epochs=20,\n",
    "    shuffle=True)\n",
    "\n",
    "eeg_classifier.train(\n",
    "    input_fn=train_input_fn,\n",
    "    steps=100,\n",
    "    hooks=[logging_hook])\n",
    "\n",
    "eval_train_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": X_train},\n",
    "    y=y_train,\n",
    "    num_epochs=1,\n",
    "    shuffle=False)\n",
    "eval_train_results = eeg_classifier.evaluate(input_fn=eval_train_fn)\n",
    "\n",
    "eval_test_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": X_test},\n",
    "    y=y_test,\n",
    "    num_epochs=1,\n",
    "    shuffle=False)\n",
    "eval_test_results = eeg_classifier.evaluate(input_fn=eval_test_fn)\n",
    "print('Train results are:',eval_train_results)\n",
    "print('Test results are:',eval_test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = import_data(every=False)\n",
    "X_train,X_test,y_train,y_test = train_test_total(X, y)\n",
    "eeg_classifier = tf.estimator.Estimator(model_fn=rnn_model, \n",
    "                                        params = {'hidden_layers' : [64], 'num_classes' : 4, 'learning_rate' : 0.001})\n",
    "tensors_to_log = {\"probabilities\": \"softmax_tensor\"}\n",
    "logging_hook = tf.train.LoggingTensorHook(\n",
    "  tensors=tensors_to_log, every_n_iter=50)\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": X_train},\n",
    "    y=y_train,\n",
    "    batch_size=100,\n",
    "    num_epochs=20,\n",
    "    shuffle=True)\n",
    "\n",
    "eeg_classifier.train(\n",
    "    input_fn=train_input_fn,\n",
    "    steps=100,\n",
    "    hooks=[logging_hook])\n",
    "\n",
    "eval_train_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": X_train},\n",
    "    y=y_train,\n",
    "    num_epochs=1,\n",
    "    shuffle=False)\n",
    "eval_train_results = eeg_classifier.evaluate(input_fn=eval_train_fn)\n",
    "\n",
    "eval_test_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": X_test},\n",
    "    y=y_test,\n",
    "    num_epochs=1,\n",
    "    shuffle=False)\n",
    "eval_test_results = eeg_classifier.evaluate(input_fn=eval_test_fn)\n",
    "print('Train results are:',eval_train_results)\n",
    "print('Test results are:',eval_test_results)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
